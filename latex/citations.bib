
@article{welanderGenerativeAdversarialNetworks2018,
	title = {Generative Adversarial Networks for Image-to-Image Translation on Multi-Contrast {MR} Images - A Comparison of {CycleGAN} and {UNIT}},
	url = {http://arxiv.org/abs/1806.07777},
	abstract = {In medical imaging, a general problem is that it is costly and time consuming to collect high quality data from healthy and diseased subjects. Generative adversarial networks ({GANs}) is a deep learning method that has been developed for synthesizing data. {GANs} can thereby be used to generate more realistic training data, to improve classification performance of machine learning algorithms. Another application of {GANs} is image-to-image translations, e.g. generating magnetic resonance ({MR}) images from computed tomography ({CT}) images, which can be used to obtain multimodal datasets from a single modality. Here, we evaluate two unsupervised {GAN} models ({CycleGAN} and {UNIT}) for image-to-image translation of T1- and T2-weighted {MR} images, by comparing generated synthetic {MR} images to ground truth images. We also evaluate two supervised models; a modification of {CycleGAN} and a pure generator model. A small perceptual study was also performed to evaluate how visually realistic the synthesized images are. It is shown that the implemented {GAN} models can synthesize visually realistic {MR} images (incorrectly labeled as real by a human). It is also shown that models producing more visually realistic synthetic images not necessarily have better quantitative error measurements, when compared to ground truth data. Code is available at https://github.com/simontomaskarlsson/{GAN}-{MRI}},
	journaltitle = {{arXiv}:1806.07777 [cs]},
	author = {Welander, Per and Karlsson, Simon and Eklund, Anders},
	urldate = {2021-05-31},
	date = {2018-06-20},
	eprinttype = {arxiv},
	eprint = {1806.07777},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\yochien\\Zotero\\storage\\EZYLEADH\\Welander 等。 - 2018 - Generative Adversarial Networks for Image-to-Image.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\CCTD8ENY\\1806.html:text/html},
}

@inproceedings{songNoncontrastCTLiver2020,
	location = {Cham},
	title = {Non-contrast {CT} Liver Segmentation Using {CycleGAN} Data Augmentation from Contrast Enhanced {CT}},
	isbn = {978-3-030-61166-8},
	doi = {10.1007/978-3-030-61166-8_13},
	series = {Lecture Notes in Computer Science},
	abstract = {Non-contrast {CT} is often preferred in clinical screening while segmentation of such {CT} data is more challenging due to the low contrast in tissue boundaries and scarce supervised training data than contrast-enhanced {CT} ({CTce}) segmentation. To alleviate manual labelling work of radiologists, we generate training samples for 3D U-Net segmentation network by transforming the existing {CTce} liver segmentation dataset to the non-contrast {CT} styled volumes with {CycleGAN}. We validated the performance of {CycleGAN} in both unsupervised and hybrid supervised training strategy. The results show that using {CycleGAN} in unsupervised segmentation can achieve higher mean Dice coefficients than fully supervised manner in liver segmentation. The hybrid training of generated samples and the target task samples can improve the generalization ability of segmentation.},
	pages = {122--129},
	booktitle = {Interpretable and Annotation-Efficient Learning for Medical Image Computing},
	publisher = {Springer International Publishing},
	author = {Song, Chongchong and He, Baochun and Chen, Hongyu and Jia, Shuangfu and Chen, Xiaoxia and Jia, Fucang},
	editor = {Cardoso, Jaime and Van Nguyen, Hien and Heller, Nicholas and Henriques Abreu, Pedro and Isgum, Ivana and Silva, Wilson and Cruz, Ricardo and Pereira Amorim, Jose and Patel, Vishal and Roysam, Badri and Zhou, Kevin and Jiang, Steve and Le, Ngan and Luu, Khoa and Sznitman, Raphael and Cheplygina, Veronika and Mateus, Diana and Trucco, Emanuele and Abbasi, Samaneh},
	date = {2020},
	langid = {english},
	keywords = {3D U-Net, {CycleGAN}, Data augmentation, Liver segmentation, Non-contrast {CT}},
	file = {Springer Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\HWIUFGAQ\\Song 等。 - 2020 - Non-contrast CT Liver Segmentation Using CycleGAN .pdf:application/pdf},
}

@article{tuladharAutomaticSegmentationStroke2020,
	title = {Automatic Segmentation of Stroke Lesions in Non-Contrast Computed Tomography Datasets With Convolutional Neural Networks},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.2995632},
	abstract = {Non-contrast computed tomography ({NCCT}) is commonly used for volumetric follow-up assessment of ischemic strokes. However, manual lesion segmentation is time-consuming and subject to high inter-observer variability. The aim of this study was to develop and establish a baseline convolutional neural network ({CNN}) model for automatic {NCCT} lesion segmentation. A total of 252 multi-center clinical {NCCT} datasets, acquired from 22 centers, and corresponding manual segmentations were used to train (204 datasets) and validate (48 datasets) a 3D multi-scale {CNN} model for lesion segmentation. Post-processing methods were implemented to improve the {CNN}-based lesion segmentations. The final {CNN} model and post-processing method was evaluated using 39 out-of-distribution holdout test datasets, acquired at seven centers that did not contribute to the training or validation datasets. Each test image was segmented by two or three neuroradiologists. The Dice similarity coefficient ({DSC}) and predicted lesion volumes were used to evaluate the segmentations. The {CNN} model achieved a mean {DSC} score of 0.47 on the validation {NCCT} datasets. Post-processing significantly improved the {DSC} to 0.50 (P {\textless}; 0.01). On the holdout test set, the {CNN} model achieved a mean {DSC} score of 0.42, which was also significantly improved to 0.45 (P {\textless}; 0.05) by post-processing. Importantly, the automatically segmented lesion volumes were not significantly different from the lesion volumes determined by the expert observers (P {\textgreater}0.05) and showed excellent agreement with manual lesion segmentation volumes (intraclass correlation coefficient, {ICC} = 0.88). The proposed {CNN} model can automatically and reliably segment ischemic stroke lesions in clinical {NCCT} datasets. Post-processing techniques can further improve accuracy. As the model was trained and evaluated on datasets from multiple centers, it is broadly applicable and is publicly available.},
	pages = {94871--94879},
	journaltitle = {{IEEE} Access},
	author = {Tuladhar, Anup and Schimert, Serena and Rajashekar, Deepthi and Kniep, Helge C. and Fiehler, Jens and Forkert, Nils D.},
	date = {2020},
	note = {Conference Name: {IEEE} Access},
	keywords = {Artificial neural networks, brain, Computational modeling, computed tomography, Computed tomography, computer-assisted image analysis, convolutional neural networks, deep learning, Image segmentation, Lesions, machine learning, Manuals, Observers, stroke, Training},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\yochien\\Zotero\\storage\\L63QMHRM\\9096283.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\4TWRBFUN\\Tuladhar 等。 - 2020 - Automatic Segmentation of Stroke Lesions in Non-Co.pdf:application/pdf},
}

@article{porterHippocampusSegmentationNoncontrast2020,
	title = {Hippocampus segmentation on noncontrast {CT} using deep learning},
	volume = {47},
	issn = {2473-4209},
	doi = {10.1002/mp.14098},
	abstract = {{PURPOSE}: Accurate segmentation of the hippocampus for hippocampal avoidance whole-brain radiotherapy currently requires high-resolution magnetic resonance imaging ({MRI}) in addition to neuroanatomic expertise for manual segmentation. Removing the need for {MR} images to identify the hippocampus would reduce planning complexity, the need for a treatment planning {MR} imaging session, potential uncertainties associated with {MRI}-computed tomography ({CT}) image registration, and cost. Three-dimensional (3D) deep convolutional network models have the potential to automate hippocampal segmentation. In this study, we investigate the accuracy and reliability of hippocampal segmentation by automated deep learning models from {CT} alone and compare the accuracy to experts using {MRI} fusion.
{METHODS}: Retrospectively, 390 Gamma Knife patients with high-resolution {CT} and {MR} images were collected. Following the {RTOG} 0933 guidelines, images were rigidly fused, and a neuroanatomic expert contoured the hippocampus on the {MR}, then transferred the contours to {CT}. Using a calculated cranial centroid, the image volumes were cropped to 200 × 200 × 35 voxels, which were used to train four models, including our proposed Attention-Gated 3D {ResNet} ({AG}-3D {ResNet}). These models were then compared with results from a nested tenfold validation. From the predicted test set volumes, we calculated the 100\% Hausdorff distance ({HD}). Acceptability was assessed using the {RTOG} 0933 protocol criteria, and contours were considered passing with {HD} ≤ 7 mm.
{RESULTS}: The bilateral hippocampus passing rate across all 90 models trained in the nested cross-fold validation was 80.2\% for {AG}-3D {ResNet}, which performs with a comparable pass rate (P = 0.3345) to physicians during centralized review for the {RTOG} 0933 Phase {II} clinical trial.
{CONCLUSIONS}: Our proposed {AG}-3D {ResNet}'s segmentation of the hippocampus from noncontrast {CT} images alone are comparable to those obtained by participating physicians from the {RTOG} 0933 Phase {II} clinical trial.},
	pages = {2950--2961},
	number = {7},
	journaltitle = {Medical Physics},
	shortjournal = {Med Phys},
	author = {Porter, Evan and Fuentes, Patricia and Siddiqui, Zaid and Thompson, Andrew and Levitin, Ronald and Solis, David and Myziuk, Nick and Guerrero, Thomas},
	date = {2020-07},
	pmid = {32065401},
	keywords = {deep learning, attention gating, {CT}, Deep Learning, hippocampus, Hippocampus, Humans, Image Processing, Computer-Assisted, Magnetic Resonance Imaging, Reproducibility of Results, {ResNet}, Retrospective Studies, segmentation, Tomography, X-Ray Computed, U-Net, whole-brain radiotherapy},
}

@article{shahzadAutomaticSegmentationQuantification2017,
	title = {Automatic segmentation and quantification of the cardiac structures from non-contrast-enhanced cardiac {CT} scans},
	volume = {62},
	issn = {1361-6560},
	doi = {10.1088/1361-6560/aa63cb},
	abstract = {Early structural changes to the heart, including the chambers and the coronary arteries, provide important information on pre-clinical heart disease like cardiac failure. Currently, contrast-enhanced cardiac computed tomography angiography ({CCTA}) is the preferred modality for the visualization of the cardiac chambers and the coronaries. In clinical practice not every patient undergoes a {CCTA} scan; many patients receive only a non-contrast-enhanced calcium scoring {CT} scan ({CTCS}), which has less radiation dose and does not require the administration of contrast agent. Quantifying cardiac structures in such images is challenging, as they lack the contrast present in {CCTA} scans. Such quantification would however be relevant, as it enables population based studies with only a {CTCS} scan. The purpose of this work is therefore to investigate the feasibility of automatic segmentation and quantification of cardiac structures viz whole heart, left atrium, left ventricle, right atrium, right ventricle and aortic root from {CTCS} scans. A fully automatic multi-atlas-based segmentation approach is used to segment the cardiac structures. Results show that the segmentation overlap between the automatic method and that of the reference standard have a Dice similarity coefficient of 0.91 on average for the cardiac chambers. The mean surface-to-surface distance error over all the cardiac structures is [Formula: see text] mm. The automatically obtained cardiac chamber volumes using the {CTCS} scans have an excellent correlation when compared to the volumes in corresponding {CCTA} scans, a Pearson correlation coefficient (R) of 0.95 is obtained. Our fully automatic method enables large-scale assessment of cardiac structures on non-contrast-enhanced {CT} scans.},
	pages = {3798--3813},
	number = {9},
	journaltitle = {Physics in Medicine and Biology},
	shortjournal = {Phys Med Biol},
	author = {Shahzad, Rahil and Bos, Daniel and Budde, Ricardo P. J. and Pellikaan, Karlijn and Niessen, Wiro J. and van der Lugt, Aad and van Walsum, Theo},
	date = {2017-05-07},
	pmid = {28248196},
	keywords = {Humans, Adult, Aged, Computed Tomography Angiography, Coronary Angiography, Male, Middle Aged},
}

@article{avila-montesSegmentationThoracicAorta2013,
	title = {Segmentation of the Thoracic Aorta in Noncontrast Cardiac {CT} Images},
	volume = {17},
	issn = {2168-2208},
	doi = {10.1109/JBHI.2013.2269292},
	abstract = {Studies have shown that aortic calcification is associated with cardiovascular disease. In this study, a method for localization, centerline extraction, and segmentation of the thoracic aorta in noncontrast cardiac-computed tomography ({CT}) images, toward the detection of aortic calcification, is presented. The localization of the right coronary artery ostium slice is formulated as a regression problem whose input variables are obtained from simple intensity features computed from a pyramid representation of the slice. The localization, centerline extraction, and segmentation of the aorta are formulated as optimal path detection problems. Dynamic programming is applied in the Hough space for localizing key center points in the aorta which guide the centerline tracing using a fast marching-based minimal path extraction framework. The input volume is then resampled into a stack of 2-D cross-sectional planes orthogonal to the obtained centerline. Dynamic programming is again applied for the segmentation of the aorta in each slice of the resampled volume. The obtained segmentation is finally mapped back to its original volume space. The performance of the proposed method was assessed on cardiac noncontrast {CT} scans and promising results were obtained.},
	pages = {936--949},
	number = {5},
	journaltitle = {{IEEE} Journal of Biomedical and Health Informatics},
	author = {Avila-Montes, Olga C. and Kurkure, Uday and Nakazato, Ryo and Berman, Daniel S. and Dey, Damini and Kakadiaris, Ioannis A.},
	date = {2013-09},
	note = {Conference Name: {IEEE} Journal of Biomedical and Health Informatics},
	keywords = {Computed tomography, Image segmentation, Aorta, Cardiology, image segmentation, Medical image processing, noncontrast computed tomography, regression, slice localization},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\NHKVQFUA\\Avila-Montes 等。 - 2013 - Segmentation of the Thoracic Aorta in Noncontrast .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\yochien\\Zotero\\storage\\BPQRCWPZ\\6542633.html:text/html},
}

@incollection{ellisTrialingUNetTraining2021,
	title = {Trialing U-Net Training Modifications for Segmenting Gliomas Using Open Source Deep Learning Framework},
	isbn = {978-3-030-72086-5},
	abstract = {Automatic brain segmentation has the potential to save time and resources for researchers and clinicians. We aimed to improve upon previously proposed methods by implementing the U-Net model and trialing various modifications to the training and inference strategies. The trials were performed and tested on the Multimodal Brain Tumor Segmentation dataset that provides {MR} images of brain tumors along with manual segmentations for hundreds of subjects. The U-Net models were trained on a training set of {MR} images from 369 subjects and then tested against a validation set of images from 125 subjects. The proposed modifications included predicting the labeled region contours, permutations of the input data via rotation and reflection, grouping labels together, as well as creating an ensemble of models. The ensemble of models provided the best results compared to any of the other methods, but the other modifications did not demonstrate improvement. Future work will look at reducing the level of the training augmentation so that the models are better able to generalize to the validation set. Overall, our open source deep learning framework allowed us to quickly implement and test multiple U-Net training modifications. The code for this project is available at https://github.com/ellisdg/3DUnetCNN.},
	pages = {40--49},
	author = {Ellis, David and Aizenberg, Michele},
	date = {2021-03-26},
	doi = {10.1007/978-3-030-72087-2_4},
	file = {Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\2JND5A54\\Ellis 與 Aizenberg - 2021 - Trialing U-Net Training Modifications for Segmenti.pdf:application/pdf},
}

@article{yushkevichUserGuided3DActive2006,
	title = {User-Guided 3D Active Contour Segmentation of Anatomical Structures: Significantly Improved Efficiency and Reliability},
	volume = {31},
	pages = {1116--1128},
	number = {3},
	journaltitle = {Neuroimage},
	author = {Yushkevich, Paul A. and Piven, Joseph and Cody Hazlett, Heather and Gimpel Smith, Rachel and Ho, Sean and Gee, James C. and Gerig, Guido},
	date = {2006},
}

@inproceedings{isolaImagetoImageTranslationConditional2017,
	title = {Image-to-Image Translation with Conditional Adversarial Networks},
	booktitle = {Computer Vision and Pattern Recognition ({CVPR}), 2017 {IEEE} Conference on},
	author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
	date = {2017},
}

@online{weishengfulibutongjichu108NianGuoRenSiYinTongJiJieGuo2020,
	title = {108年國人死因統計結果},
	rights = {衛生福利部統計處},
	url = {https://www.mohw.gov.tw/cp-16-54482-1.html},
	abstract = {一、受人口高齡化影響，108年死亡率上升1.4\%，標準化死亡率下降1.6\%{\textless}/},
	titleaddon = {衛生福利部統計處},
	type = {文字},
	author = {衛生福利部統計處},
	urldate = {2021-06-02},
	date = {2020-06-16},
	note = {Publisher: 衛生福利部統計處},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\RG5AY5KW\\cp-16-54482-1.html:text/html},
}

@online{weishengfulibutongjichuSiYinTongJi2017,
	title = {死因統計},
	rights = {衛生福利部統計處},
	url = {https://dep.mohw.gov.tw/DOS/np-1776-113.html},
	abstract = {死因統計},
	titleaddon = {衛生福利部統計處},
	type = {文字},
	author = {衛生福利部統計處},
	urldate = {2021-06-02},
	date = {2017-01-24},
	note = {Publisher: 衛生福利部統計處},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\XYIJI2FT\\np-1776-113.html:text/html},
}

@online{weishengfulibuguominjiankangshuRenShiGuanXinBing2016,
	title = {認識冠心病},
	rights = {衛生福利部國民健康署},
	url = {https://www.hpa.gov.tw/Pages/Detail.aspx?nodeid=632&pid=1188},
	abstract = {\&nbsp;
認識冠心病

從心說起：
正常心臟是一個強壯的、中空的肌肉組織，約拳頭般大。位於胸腔內胸骨之後。負責輸送血液至全身。一般健康的人每天心跳約十萬次，要打出8000公升以上的血液，流經全身各處，而且每天廿四小時不眠不休的，為維持人體正常運作而努力。為了維持這樣長年不休的劇烈運動，心},
	titleaddon = {衛生福利部國民健康署},
	type = {text/html},
	author = {衛生福利部國民健康署},
	urldate = {2021-06-02},
	date = {2016-12-31},
	langid = {pinyin},
	note = {Archive Location: 涵蓋範圍
Publisher: 衛生福利部國民健康署},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\N7YQ8E5R\\Detail.html:text/html},
}

@article{klimontDeepLearningCerebral2020,
	title = {Deep learning for cerebral angiography segmentation from non-contrast computed tomography},
	volume = {15},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0237092},
	abstract = {Cerebral computed tomography angiography is a widely available imaging technique that helps in the diagnosis of vascular pathologies. Contrast administration is needed to accurately assess the arteries. On non-contrast computed tomography, arteries are hardly distinguishable from the brain tissue, therefore, radiologists do not consider this imaging modality appropriate for the evaluation of vascular pathologies. There are known contraindications to administering iodinated contrast media, and in these cases, the patient has to undergo another examination to visualize cerebral arteries, such as magnetic resonance angiography. Deep learning for image segmentation has proven to perform well on medical data for a variety of tasks. The aim of this research was to apply deep learning methods to segment cerebral arteries on non-contrast computed tomography scans and consequently, generate angiographies without the need for contrast administration. The dataset for this research included 131 patients who underwent brain non-contrast computed tomography directly followed by computed tomography with contrast administration. Then, the segmentations of arteries were generated and aligned with non-contrast computed tomography scans. A deep learning model based on the U-net architecture was trained to perform the segmentation of blood vessels on non-contrast computed tomography. An evaluation was performed on separate test data, as well as using cross-validation, reaching Dice coefficients of 0.638 and 0.673, respectively. This study proves that deep learning methods can be leveraged to quickly solve problems that are difficult and time-consuming for a human observer, therefore providing physicians with additional information on the patient. To encourage the further development of similar tools, all code used for this research is publicly available.},
	pages = {e0237092},
	number = {7},
	journaltitle = {{PloS} One},
	shortjournal = {{PLoS} One},
	author = {Klimont, Michał and Oronowicz-Jaśkowiak, Agnieszka and Flieger, Mateusz and Rzeszutek, Jacek and Juszkat, Robert and Jończyk-Potoczna, Katarzyna},
	date = {2020},
	pmid = {32735633},
	pmcid = {PMC7394424},
	keywords = {Deep Learning, Humans, Image Processing, Computer-Assisted, Retrospective Studies, Computed Tomography Angiography, Male, Brain, Cerebral Angiography, Contrast Media, Female},
	file = {全文:C\:\\Users\\yochien\\Zotero\\storage\\U2YILZDS\\Klimont 等。 - 2020 - Deep learning for cerebral angiography segmentatio.pdf:application/pdf},
}

@inreference{XSheXianJiSuanJiDuanCengChengXiang2021,
	title = {X射线计算机断层成像},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://zh.wikipedia.org/w/index.php?title=X%E5%B0%84%E7%BA%BF%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%96%AD%E5%B1%82%E6%88%90%E5%83%8F&oldid=65446763},
	abstract = {電腦斷層掃描（Computed Tomography，簡稱{CT}），是一種影像診斷學的檢查。這一技術曾被稱為電腦軸向斷層掃描（Computed Axial Tomography）。它使用從不同角度進行的許多X射線測量值的計算機處理組合來生成特定掃描區域的橫截面（斷層）圖像（虛擬「切片」） 物體，使用戶無需切割即可看到物體內部。1979年諾貝爾生理學或醫學獎因「計算機輔助層析成像技術的發展」而共同授予南非裔美國物理學家阿蘭·科馬克(Allan M. Cormack)和英國電氣工程師高弗雷·豪斯費爾德(Godfrey N. Hounsfield)。
X射線電腦斷層掃描（X-Ray Computed Tomography，簡稱X-{CT}）是一種利用數位幾何處理後重建的三維放射線醫學影像。該技術主要通過單一軸面的X射線旋轉照射人體，由於不同的組織對X射線的吸收能力（或稱阻射率）不同，可以用電腦的三維技術重建出斷層面影像。經由窗口技術處理，可以得到相應組織的斷層影像。將斷層影像層層堆疊，即可形成立體影像。},
	booktitle = {維基百科，自由的百科全書},
	urldate = {2021-06-02},
	date = {2021-05-02},
	langid = {pinyin},
	note = {Page Version {ID}: 65446763},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\DL22MLKT\\index.html:text/html},
}

@article{seeramComputedTomographyTechnical2018,
	title = {Computed Tomography: A Technical Review},
	volume = {89},
	issn = {1943-5657},
	shorttitle = {Computed Tomography},
	abstract = {Computed tomography ({CT}) is a technical and complex diagnostic imaging modality. Radiologic technologists must understand the technology well enough to optimize dose and image quality and provide excellent patient care. This article reviews essential physical principles and technical aspects of {CT}, including physics related to radiation attenuation and {CT} numbers along with general technical concepts. In addition, the article reviews multislice {CT} technology.},
	pages = {279CT--302CT},
	number = {3},
	journaltitle = {Radiologic Technology},
	shortjournal = {Radiol Technol},
	author = {Seeram, Euclid},
	date = {2018-01},
	pmid = {29298954},
	keywords = {Humans, Tomography, X-Ray Computed, Imaging, Three-Dimensional, Physics, Radiation Dosage, Radiation Protection, Radiographic Image Interpretation, Computer-Assisted},
}

@article{huynhUpdatedGuidelinesIntravenous2020,
	title = {Updated guidelines for intravenous contrast use for {CT} and {MRI}},
	volume = {27},
	issn = {1438-1435},
	doi = {10.1007/s10140-020-01751-y},
	abstract = {Intravenous ({IV}) contrast material is used extensively for {CT} and {MRI} scans done in emergency departments ({ED}). Its use is essential to make many critical diagnoses in {ED} patients. While adverse reactions can occur, newer research has added to our knowledge of {IV} contrast media tolerance and safety leading to improved and more liberal guidelines for intravenous contrast use. The updated information described in this review article indicates how intravenous contrast can be used safely in more patients, more expeditiously and with fewer precautions than with prior guidelines. This review article explains the basis for the new recommendations for intravenous contrast material use and describes indicated precautions and preparations to avoid adverse reactions for iodinated agents used for {CT} and gadolinium agents for {MRI}.},
	pages = {115--126},
	number = {2},
	journaltitle = {Emergency Radiology},
	shortjournal = {Emerg Radiol},
	author = {Huynh, Kevin and Baghdanian, Arthur H. and Baghdanian, Armonde A. and Sun, Derek S. and Kolli, K. Pallav and Zagoria, Ronald J.},
	date = {2020-04},
	pmid = {31925592},
	keywords = {{CT}, Humans, Magnetic Resonance Imaging, Tomography, X-Ray Computed, Contrast Media, Contrast material, Drug Hypersensitivity, Emergency radiology, Emergency Service, Hospital, Gadolinium, Injections, Intravenous, {MRI}, Practice Guidelines as Topic, Risk Factors, Safety Management},
}

@article{minaeeImageSegmentationUsing2021,
	title = {Image Segmentation Using Deep Learning: A Survey},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2021.3059968},
	shorttitle = {Image Segmentation Using Deep Learning},
	abstract = {Image segmentation is a key task in computer vision and image processing with important applications such as scene understanding, medical image analysis, robotic perception, video surveillance, augmented reality, and image compression, among others, and numerous segmentation algorithms are found in the literature. Against this backdrop, the broad success of Deep Learning ({DL}) has prompted the development of new image segmentation approaches leveraging {DL} models. We provide a comprehensive review of this recent literature, covering the spectrum of pioneering efforts in semantic and instance segmentation, including convolutional pixel-labeling networks, encoder-decoder architectures, multiscale and pyramid-based approaches, recurrent networks, visual attention models, and generative models in adversarial settings. We investigate the relationships, strengths, and challenges of these {DL}-based segmentation models, examine the widely used datasets, compare performances, and discuss promising research directions.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Minaee, Shervin and Boykov, Yuri Y. and Porikli, Fatih and Plaza, Antonio J and Kehtarnavaz, Nasser and Terzopoulos, Demetri},
	date = {2021},
	note = {Conference Name: {IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Computational modeling, convolutional neural networks, deep learning, Image segmentation, Deep learning, Computer architecture, encoder-decoder models, Generative adversarial networks, generative models, instance segmentation, Logic gates, medical image segmentation, panoptic segmentation, recurrent models, semantic segmentation, Semantics},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\yochien\\Zotero\\storage\\89MBK2KT\\9356353.html:text/html;送出的版本:C\:\\Users\\yochien\\Zotero\\storage\\DC98AWXY\\Minaee 等。 - 2021 - Image Segmentation Using Deep Learning A Survey.pdf:application/pdf},
}

@article{litjensSurveyDeepLearning2017,
	title = {A survey on deep learning in medical image analysis},
	volume = {42},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841517301135},
	doi = {10.1016/j.media.2017.07.005},
	abstract = {Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks. Concise overviews are provided of studies per application area: neuro, retinal, pulmonary, digital pathology, breast, cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art, a critical discussion of open challenges and directions for future research.},
	pages = {60--88},
	journaltitle = {Medical Image Analysis},
	shortjournal = {Medical Image Analysis},
	author = {Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen A. W. M. and van Ginneken, Bram and Sánchez, Clara I.},
	urldate = {2021-06-02},
	date = {2017-12-01},
	langid = {english},
	keywords = {Deep learning, Convolutional neural networks, Medical imaging, Survey},
	file = {ScienceDirect Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\UFGYJ5DI\\S1361841517301135.html:text/html;送出的版本:C\:\\Users\\yochien\\Zotero\\storage\\94Y7QNWM\\Litjens 等。 - 2017 - A survey on deep learning in medical image analysi.pdf:application/pdf},
}

@article{chenDeepLearningCardiac2020,
	title = {Deep Learning for Cardiac Image Segmentation: A Review},
	volume = {7},
	issn = {2297-055X},
	url = {https://www.frontiersin.org/articles/10.3389/fcvm.2020.00025/full},
	doi = {10.3389/fcvm.2020.00025},
	shorttitle = {Deep Learning for Cardiac Image Segmentation},
	abstract = {Deep learning has become the most widely used approach for cardiac image segmentation in recent years. In this paper, we provide a review of over 100 cardiac image segmentation papers using deep learning, which covers common imaging modalities including magnetic resonance imaging ({MRI}), computed tomography ({CT}), and ultrasound and major anatomical structures of interest (ventricles, atria and vessels). In addition, a summary of publicly available cardiac image datasets and code repositories are included to provide a base for encouraging reproducible research. Finally, we discuss the challenges and limitations with current deep learning-based approaches (scarcity of labels, model generalizability across different domains, interpretability) and suggest potential directions for future research.},
	journaltitle = {Frontiers in Cardiovascular Medicine},
	shortjournal = {Front. Cardiovasc. Med.},
	author = {Chen, Chen and Qin, Chen and Qiu, Huaqi and Tarroni, Giacomo and Duan, Jinming and Bai, Wenjia and Rueckert, Daniel},
	urldate = {2021-06-02},
	date = {2020},
	note = {Publisher: Frontiers},
	keywords = {deep learning, {CT}, {MRI}, artificial intelligence, Cardiac Image Analysis, Cardiac image segmentation, neural networks, ultrasound},
	file = {Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\GJZ3RU38\\Chen 等。 - 2020 - Deep Learning for Cardiac Image Segmentation A Re.pdf:application/pdf},
}

@inproceedings{huangCoronaryArterySegmentation2018,
	title = {Coronary Artery Segmentation by Deep Learning Neural Networks on Computed Tomographic Coronary Angiographic Images},
	doi = {10.1109/EMBC.2018.8512328},
	abstract = {Coronary artery lumen delineation, to localize and grade stenosis, is an important but tedious and challenging task for coronary heart disease evaluation. Deep learning has recently been successful applied to many applications, including medical imaging. However for small imaged objects such as coronary arteries and their segmentation, it remains a challenge. This paper investigates coronary artery lumen segmentation using 3D U-net convolutional neural networks, and tests its utility with multiple datasets on two settings. We adapted the computed tomography coronary angiography ({CTCA}) volumes into small patches for the networks and tuned the kernels, layers and the batch size for machine learning. Our experiment involves additional efforts to select and test various data transform, so as to reduce the problem of overfitting. Compared with traditional normalization of data, we showed that subject-specific normalization of dataset was superior to patch based normalization. The results also showed that the proposed deep learning approach outperformed other methods, evaluated by the Dice coefficients.},
	eventtitle = {2018 40th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
	pages = {608--611},
	booktitle = {2018 40th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
	author = {Huang, Weimin and Huang, Lu and Lin, Zhiping and Huang, Su and Chi, Yanling and Zhou, Jiayin and Zhang, Junmei and Tan, Ru-San and Zhong, Liang},
	date = {2018-07},
	note = {{ISSN}: 1558-4615},
	keywords = {Image segmentation, Training, Arteries, Testing, Three-dimensional displays, Two dimensional displays},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\TLJXAJNA\\Huang 等。 - 2018 - Coronary Artery Segmentation by Deep Learning Neur.pdf:application/pdf},
}

@inreference{CoronaryCTCalcium2021,
	title = {Coronary {CT} calcium scan},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Coronary_CT_calcium_scan&oldid=1016880505},
	abstract = {A coronary {CT} calcium scan is a computed tomography ({CT}) scan of the heart for the assessment of severity of coronary artery disease. Specifically, it looks for calcium deposits in the coronary arteries that can narrow arteries and increase the risk of heart attack. This severity can be presented as Agatston score or coronary artery calcium ({CAC}) score. The {CAC} score is an independent marker of risk for cardiac events, cardiac mortality, and all-cause mortality. In addition, it provides additional prognostic information to other cardiovascular risk markers. A typical coronary {CT} calcium scan is done without the use of radiocontrast, but it can possibly be done from contrast-enhanced images as well, such as in coronary {CT} angiography.},
	booktitle = {Wikipedia},
	urldate = {2021-06-02},
	date = {2021-04-09},
	langid = {english},
	note = {Page Version {ID}: 1016880505},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\L9KMWTMX\\index.html:text/html},
}

@article{blahaCoronaryArteryCalcium2017,
	title = {Coronary Artery Calcium Scoring: Is It Time for a Change in Methodology?},
	volume = {10},
	issn = {1936-878X},
	url = {https://www.sciencedirect.com/science/article/pii/S1936878X17305041},
	doi = {10.1016/j.jcmg.2017.05.007},
	shorttitle = {Coronary Artery Calcium Scoring},
	abstract = {Quantification of coronary artery calcium ({CAC}) has been shown to be reliable, reproducible, and predictive of cardiovascular risk. Formal {CAC} scoring was introduced in 1990, with early scoring algorithms notable for their simplicity and elegance. Yet, with little evidence available on how to best build a score, and without a conceptual model guiding score development, these scores were, to a large degree, arbitrary. In this review, we describe the traditional approaches for clinical {CAC} scoring, noting their strengths, weaknesses, and limitations. We then discuss a conceptual model for developing an improved {CAC} score, reviewing the evidence supporting approaches most likely to lead to meaningful score improvement (for example, accounting for {CAC} density and regional distribution). After discussing the potential implementation of an improved score in clinical practice, we follow with a discussion of the future of {CAC} scoring, asking the central question: do we really need a new {CAC} score?},
	pages = {923--937},
	number = {8},
	journaltitle = {{JACC}: Cardiovascular Imaging},
	shortjournal = {{JACC}: Cardiovascular Imaging},
	author = {Blaha, Michael J. and Mortensen, Martin Bødtker and Kianoush, Sina and Tota-Maharaj, Rajesh and Cainzos-Achirica, Miguel},
	urldate = {2021-06-02},
	date = {2017-08-01},
	langid = {english},
	keywords = {cardiac {CT}, cardiovascular disease, coronary artery calcium, prediction, risk, score},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\A9P7RYFK\\Blaha 等。 - 2017 - Coronary Artery Calcium Scoring Is It Time for a .pdf:application/pdf},
}

@article{leiMedicalImageSegmentation2020,
	title = {Medical Image Segmentation Using Deep Learning: A Survey},
	url = {http://arxiv.org/abs/2009.13120},
	shorttitle = {Medical Image Segmentation Using Deep Learning},
	abstract = {Deep learning has been widely used for medical image segmentation and a large number of papers has been presented recording the success of deep learning in the field. In this paper, we present a comprehensive thematic survey on medical image segmentation using deep learning techniques. This paper makes two original contributions. Firstly, compared to traditional surveys that directly divide literatures of deep learning on medical image segmentation into many groups and introduce literatures in detail for each group, we classify currently popular literatures according to a multi-level structure from coarse to fine. Secondly, this paper focuses on supervised and weakly supervised learning approaches, without including unsupervised approaches since they have been introduced in many old surveys and they are not popular currently. For supervised learning approaches, we analyze literatures in three aspects: the selection of backbone networks, the design of network blocks, and the improvement of loss functions. For weakly supervised learning approaches, we investigate literature according to data augmentation, transfer learning, and interactive segmentation, separately. Compared to existing surveys, this survey classifies the literatures very differently from before and is more convenient for readers to understand the relevant rationale and will guide them to think of appropriate improvements in medical image segmentation based on deep learning approaches.},
	journaltitle = {{arXiv}:2009.13120 [cs, eess]},
	author = {Lei, Tao and Wang, Risheng and Wan, Yong and Zhang, Bingtao and Meng, Hongying and Nandi, Asoke K.},
	urldate = {2021-06-02},
	date = {2020-12-16},
	eprinttype = {arxiv},
	eprint = {2009.13120},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:C\:\\Users\\yochien\\Zotero\\storage\\TJUWEEB3\\Lei 等。 - 2020 - Medical Image Segmentation Using Deep Learning A .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\G2CRMTZQ\\2009.html:text/html},
}

@incollection{ronnebergerUNetConvolutionalNetworks2015,
	location = {Cham},
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	volume = {9351},
	isbn = {978-3-319-24573-7 978-3-319-24574-4},
	url = {http://link.springer.com/10.1007/978-3-319-24574-4_28},
	shorttitle = {U-Net},
	pages = {234--241},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	urldate = {2021-07-01},
	date = {2015},
	langid = {english},
	doi = {10.1007/978-3-319-24574-4_28},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {送出的版本:C\:\\Users\\yochien\\Zotero\\storage\\8GPK9U2Z\\Ronneberger 等。 - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf},
}

@online{HounsfieldScaleOverview,
	title = {Hounsfield Scale - an overview {\textbar} {ScienceDirect} Topics},
	url = {https://www.sciencedirect.com/topics/medicine-and-dentistry/hounsfield-scale},
	urldate = {2021-07-01},
	file = {Hounsfield Scale - an overview | ScienceDirect Topics:C\:\\Users\\yochien\\Zotero\\storage\\A28SAWAV\\hounsfield-scale.html:text/html},
}

@article{patelHounsfieldUnitsComputed2009,
	title = {Hounsfield units on computed tomography predict calcium stone subtype composition},
	volume = {83},
	issn = {1423-0399},
	doi = {10.1159/000230020},
	abstract = {{INTRODUCTION}: Hounsfield unit ({HU}) determination of urinary stones on noncontrast computed tomography ({NCCT}) has been shown to predict stone composition. However, no in vivo studies have attempted to radiographically separate the various calcium stone compositions. We investigate the efficacy of {HU} measurement on {NCCT} to determine if it can differentiate the various calcium stone subtypes.
{PATIENTS} {AND} {METHODS}: Of the 684 patients who had undergone ureteroscopy at our institution from 1/2003 to 10/2007, 100 were identified with a documented {NCCT}, a chemical stone analysis and a stone size {\textgreater}5 mm but {\textless}2 cm.
{RESULTS}: Stone compositions were categorized as 100-80\% calcium oxalate monohydrate ({CaOMH}) (n = 24), {\textless}80-60\% {CaOMH} (n = 21), {\textless}60-50\% {CaOMH} (n = 11) calcium oxalate dihydrate ({CaODH}) (n = 16), apatite (n = 9), brushite (n = 4), cystine (n = 2) and uric acid (n = 13). Mean {HU} were 879 +/- 230, 769 +/- 295, 717 +/- 304, and 517 +/- 203 for the 100-80\% {CaOMH}, {\textless}80-60\% {CaOMH}, {\textless}60-50\% {CaOMH} and {CaODH} groups, respectively. The average {HU} for the apatite, brushite, cystine and uric acid groups were 844 +/- 346, 1,123 +/- 254, 550 +/- 74 and 338 +/- 145, respectively. The {CaOMH} groups together had a significantly higher {HU} than the {CaODH} group (p {\textless} 0.05) and a significantly lower {HU} than the brushite group (p {\textless} 0.05).
{CONCLUSIONS}: {HU} measurement of urinary stones on {NCCT} may be used to separate some calcium stone subtypes, specifically {CaOMH} and {CaODH}. This information may be useful in counseling patients on treatment options for patients requiring intervention.},
	pages = {175--180},
	number = {2},
	journaltitle = {Urologia Internationalis},
	shortjournal = {Urol Int},
	author = {Patel, Sutchin R. and Haleblian, George and Zabbo, August and Pareek, Gyan},
	date = {2009},
	pmid = {19752613},
	keywords = {Humans, Retrospective Studies, Tomography, X-Ray Computed, Calcium, Predictive Value of Tests, Urinary Calculi},
}

@article{patelHounsfieldUnitsComputed2009a,
	title = {Hounsfield Units on Computed Tomography Predict Calcium Stone Subtype Composition},
	volume = {83},
	issn = {0042-1138, 1423-0399},
	url = {https://www.karger.com/Article/FullText/230020},
	doi = {10.1159/000230020},
	abstract = {\textit{Introduction:} Hounsfield unit ({HU}) determination of urinary stones on noncontrast computed tomography ({NCCT}) has been shown to predict stone composition. However, no in vivo studies have attempted to radiographically separate the various calcium stone compositions. We investigate the efficacy of {HU} measurement on {NCCT} to determine if it can differentiate the various calcium stone subtypes. \textit{Patients and Methods:} Of the 684 patients who had undergone ureteroscopy at our institution from 1/2003 to 10/2007, 100 were identified with a documented {NCCT}, a chemical stone analysis and a stone size {\textgreater}5 mm but {\textless}2 cm. \textit{Results:} Stone compositions were categorized as 100–80\% calcium oxalate monohydrate ({CaOMH}) (n = 24), {\textless}80–60\% {CaOMH} (n = 21), {\textless}60–50\% {CaOMH} (n = 11) calcium oxalate dihydrate ({CaODH}) (n = 16), apatite (n = 9), brushite (n = 4), cystine (n = 2) and uric acid (n = 13). Mean {HU} were 879 ± 230, 769 ± 295, 717 ± 304, and 517 ± 203 for the 100–80\% {CaOMH}, {\textless}80–60\% {CaOMH}, {\textless}60–50\% {CaOMH} and {CaODH} groups, respectively. The average {HU} for the apatite, brushite, cystine and uric acid groups were 844 ± 346, 1,123 ± 254, 550 ± 74 and 338 ± 145, respectively. The {CaOMH} groups together had a significantly higher {HU} than the {CaODH} group (p {\textless} 0.05) and a significantly lower {HU} than the brushite group (p {\textless} 0.05). \textit{Conclusions:} {HU} measurement of urinary stones on {NCCT} may be used to separate some calcium stone subtypes, specifically {CaOMH} and {CaODH}. This information may be useful in counseling patients on treatment options for patients requiring intervention.},
	pages = {175--180},
	number = {2},
	journaltitle = {Urologia Internationalis},
	shortjournal = {{UIN}},
	author = {Patel, Sutchin R. and Haleblian, George and Zabbo, August and Pareek, Gyan},
	urldate = {2021-07-01},
	date = {2009},
	pmid = {19752613},
	note = {Publisher: Karger Publishers},
	file = {Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\J4X6QEX6\\Patel 等。 - 2009 - Hounsfield Units on Computed Tomography Predict Ca.pdf:application/pdf},
}

@online{GuanZhuangDongMoDianNaoDuanCengZaoYingComputedTomography,
	title = {冠狀動脈電腦斷層造影(Computed tomography coronary angiography, {CTCA})},
	url = {https://smallcollation.blogspot.com/2013/11/computed-tomography-coronary.html},
	abstract = {各類基礎醫學、英文、德文、日文、俄文、法律、遊戲相關資訊
Basic medicine,English,German,Japanese,Russian,law,{PC} games},
	urldate = {2021-07-01},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\UIG5CYTE\\computed-tomography-coronary.html:text/html},
}

@online{theslicercommunity3DSlicerImage,
	title = {3D Slicer image computing platform},
	url = {https://slicer.org/},
	abstract = {3D Slicer is a free, open source and multi-platform software package widely used for medical, biomedical, and related imaging research.},
	titleaddon = {3D Slicer},
	author = {{The Slicer Community}},
	urldate = {2021-07-02},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\TBZEMHGU\\www.slicer.org.html:text/html},
}

@incollection{kikinis3DSlicerPlatform2014,
	location = {New York, {NY}},
	title = {3D Slicer: A Platform for Subject-Specific Image Analysis, Visualization, and Clinical Support},
	isbn = {978-1-4614-7657-3},
	url = {https://doi.org/10.1007/978-1-4614-7657-3_19},
	shorttitle = {3D Slicer},
	abstract = {3D Slicer is an open-source platform for the analysis and display of information derived from medical imaging and similar data sets. Such advanced software environments are in daily use by researchers and clinicians and in many nonmedical applications. 3D Slicer is unique through serving clinical users, multidisciplinary clinical research terms, and software architects within a single technology structure and user community. Functions such as interactive visualization, image registration, and model-based analysis are now being complemented by more advanced capabilities, most notably in neurological imaging and intervention. These functions, originally limited to offline use by technical factors, are integral to large scale, rapidly developing research studies, and they are being increasingly integrated into the management and delivery of care. This activity has been led by a community of basic, applied, and clinical scientists and engineers, from both academic and commercial perspectives. 3D Slicer, a free open-source software package, is based in this community; 3D Slicer provides a set of interactive tools and a stable platform that can quickly incorporate new analysis techniques and evolve to serve more sophisticated real-time applications while remaining compatible with the latest hardware and software generations of host computer systems.},
	pages = {277--289},
	booktitle = {Intraoperative Imaging and Image-Guided Therapy},
	publisher = {Springer},
	author = {Kikinis, Ron and Pieper, Steve D. and Vosburgh, Kirby G.},
	editor = {Jolesz, Ferenc A.},
	urldate = {2021-07-02},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-1-4614-7657-3_19},
	keywords = {Diffusion Magnetic Resonance Imaging, Iterative Close Point, Source Code Repository, Volume Rendering},
	file = {Springer Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\4BYDCSVC\\Kikinis 等。 - 2014 - 3D Slicer A Platform for Subject-Specific Image A.pdf:application/pdf},
}

@article{kapurIncreasingImpactMedical2016,
	title = {Increasing the impact of medical image computing using community-based open-access hackathons: The {NA}-{MIC} and 3D Slicer experience},
	volume = {33},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841516301128},
	doi = {10.1016/j.media.2016.06.035},
	series = {20th anniversary of the Medical Image Analysis journal ({MedIA})},
	shorttitle = {Increasing the impact of medical image computing using community-based open-access hackathons},
	abstract = {The National Alliance for Medical Image Computing ({NA}-{MIC}) was launched in 2004 with the goal of investigating and developing an open source software infrastructure for the extraction of information and knowledge from medical images using computational methods. Several leading research and engineering groups participated in this effort that was funded by the {US} National Institutes of Health through a variety of infrastructure grants. This effort transformed 3D Slicer from an internal, Boston-based, academic research software application into a professionally maintained, robust, open source platform with an international leadership and developer and user communities. Critical improvements to the widely used underlying open source libraries and tools—{VTK}, {ITK}, {CMake}, {CDash}, {DCMTK}—were an additional consequence of this effort. This project has contributed to close to a thousand peer-reviewed publications and a growing portfolio of {US} and international funded efforts expanding the use of these tools in new medical computing applications every year. In this editorial, we discuss what we believe are gaps in the way medical image computing is pursued today; how a well-executed research platform can enable discovery, innovation and reproducible science (“Open Science”); and how our quest to build such a software platform has evolved into a productive and rewarding social engineering exercise in building an open-access community with a shared vision.},
	pages = {176--180},
	journaltitle = {Medical Image Analysis},
	shortjournal = {Medical Image Analysis},
	author = {Kapur, Tina and Pieper, Steve and Fedorov, Andriy and Fillion-Robin, J-C and Halle, Michael and O'Donnell, Lauren and Lasso, Andras and Ungi, Tamas and Pinter, Csaba and Finet, Julien and Pujol, Sonia and Jagadeesan, Jayender and Tokuda, Junichi and Norton, Isaiah and Estepar, Raul San Jose and Gering, David and Aerts, Hugo J. W. L. and Jakab, Marianna and Hata, Nobuhiko and Ibanez, Luiz and Blezek, Daniel and Miller, Jim and Aylward, Stephen and Grimson, W. Eric L and Fichtinger, Gabor and Wells, William M and Lorensen, William E. and Schroeder, Will and Kikinis, Ron},
	urldate = {2021-07-02},
	date = {2016-10-01},
	langid = {english},
	keywords = {3D Slicer, Hackathon, Medical image computing, {NA}-{MIC}, Open access, Open science, Open source, Project week, Reproducible research},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\KP6JGMQF\\Kapur 等。 - 2016 - Increasing the impact of medical image computing u.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\Q2KA2DEH\\S1361841516301128.html:text/html},
}

@article{fedorov3DSlicerImage2012,
	title = {3D Slicer as an Image Computing Platform for the Quantitative Imaging Network},
	volume = {30},
	issn = {0730-725X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3466397/},
	doi = {10.1016/j.mri.2012.05.001},
	abstract = {Quantitative analysis has tremendous but mostly unrealized potential in healthcare to support objective and accurate interpretation of the clinical imaging. In 2008, the National Cancer Institute began building the Quantitative Imaging Network ({QIN}) initiative with the goal of advancing quantitative imaging in the context of personalized therapy and evaluation of treatment response. Computerized analysis is an important component contributing to reproducibility and efficiency of the quantitative imaging techniques. The success of quantitative imaging is contingent on robust analysis methods and software tools to bring these methods from bench to bedside., 3D Slicer is a free open source software application for medical image computing. As a clinical research tool, 3D Slicer is similar to a radiology workstation that supports versatile visualizations but also provides advanced functionality such as automated segmentation and registration for a variety of application domains. Unlike a typical radiology workstation, 3D Slicer is free and is not tied to specific hardware. As a programming platform, 3D Slicer facilitates translation and evaluation of the new quantitative methods by allowing the biomedical researcher to focus on the implementation of the algorithm, and providing abstractions for the common tasks of data communication, visualization and user interface development. Compared to other tools that provide aspects of this functionality, 3D Slicer is fully open source and can be readily extended and redistributed. In addition, 3D Slicer is designed to facilitate the development of new functionality in the form of 3D Slicer extensions., In this paper, we present an overview of 3D Slicer as a platform for prototyping, development and evaluation of image analysis tools for clinical research applications. To illustrate the utility of the platform in the scope of {QIN}, we discuss several use cases of 3D Slicer by the existing {QIN} teams, and we elaborate on the future directions that can further facilitate development and validation of imaging biomarkers using 3D Slicer.},
	pages = {1323--1341},
	number = {9},
	journaltitle = {Magnetic resonance imaging},
	shortjournal = {Magn Reson Imaging},
	author = {Fedorov, Andriy and Beichel, Reinhard and Kalpathy-Cramer, Jayashree and Finet, Julien and Fillion-Robin, Jean-Christophe and Pujol, Sonia and Bauer, Christian and Jennings, Dominique and Fennessy, Fiona and Sonka, Milan and Buatti, John and Aylward, Stephen and Miller, James V. and Pieper, Steve and Kikinis, Ron},
	urldate = {2021-07-02},
	date = {2012-11},
	pmid = {22770690},
	pmcid = {PMC3466397},
	file = {PubMed Central Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\XZSA6NPN\\Fedorov 等。 - 2012 - 3D Slicer as an Image Computing Platform for the Q.pdf:application/pdf},
}

@inproceedings{geringIntegratedVisualizationSystem1999,
	location = {Berlin, Heidelberg},
	title = {An Integrated Visualization System for Surgical Planning and Guidance Using Image Fusion and Interventional Imaging},
	isbn = {978-3-540-48232-1},
	doi = {10.1007/10704282_88},
	series = {Lecture Notes in Computer Science},
	abstract = {We present a software package which uniquely integrates several facets of image-guided medicine into a single portable, extendable environment. It provides capabilities for automatic registration, semi-automatic segmentation, 3D surface model generation, 3D visualization, and quantitative analysis of various medical scans. We describe its system architecture, wide range of applications, and novel integration with an interventional Magnetic Resonance ({MR}) scanner to augment intra-operative imaging with pre-operative data. Analysis previously reserved for pre-operative data can now be applied to exploring the anatomical changes as the surgery progresses. Surgical instruments are tracked and used to drive the location of reformatted slices. Real-time scans are visualized as slices in the same 3D view along with the pre-operative slices and surface models. The system has been applied in over 20 neurosurgical cases at Brigham and Women’s Hospital, and continues to be routinely used for 1-3 cases per week.},
	pages = {809--819},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention – {MICCAI}’99},
	publisher = {Springer},
	author = {Gering, David T. and Nabavi, Arya and Kikinis, Ron and Grimson, W. Eric L. and Hata, Noby and Everett, Peter and Jolesz, Ferenc and Wells, William M.},
	editor = {Taylor, Chris and Colchester, Alain},
	date = {1999},
	langid = {english},
	keywords = {Automatic Registration, Brain Shift, Eloquent Cortex, Surgical Guidance, Surgical Planning},
	file = {Springer Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\8GV6TUKI\\Gering 等。 - 1999 - An Integrated Visualization System for Surgical Pl.pdf:application/pdf},
}

@article{geringIntegratedVisualizationSystem2001,
	title = {An integrated visualization system for surgical planning and guidance using image fusion and an open {MR}},
	volume = {13},
	issn = {1053-1807},
	doi = {10.1002/jmri.1139},
	abstract = {A surgical guidance and visualization system is presented, which uniquely integrates capabilities for data analysis and on-line interventional guidance into the setting of interventional {MRI}. Various pre-operative scans (T1- and T2-weighted {MRI}, {MR} angiography, and functional {MRI} ({fMRI})) are fused and automatically aligned with the operating field of the interventional {MR} system. Both pre-surgical and intra-operative data may be segmented to generate three-dimensional surface models of key anatomical and functional structures. Models are combined in a three-dimensional scene along with reformatted slices that are driven by a tracked surgical device. Thus, pre-operative data augments interventional imaging to expedite tissue characterization and precise localization and targeting. As the surgery progresses, and anatomical changes subsequently reduce the relevance of pre-operative data, interventional data is refreshed for software navigation in true real time. The system has been applied in 45 neurosurgical cases and found to have beneficial utility for planning and guidance. J. Magn. Reson. Imaging 2001;13:967-975.},
	pages = {967--975},
	number = {6},
	journaltitle = {Journal of magnetic resonance imaging: {JMRI}},
	shortjournal = {J Magn Reson Imaging},
	author = {Gering, D. T. and Nabavi, A. and Kikinis, R. and Hata, N. and O'Donnell, L. J. and Grimson, W. E. and Jolesz, F. A. and Black, P. M. and Wells, W. M.},
	date = {2001-06},
	pmid = {11382961},
	keywords = {Humans, Image Processing, Computer-Assisted, Magnetic Resonance Imaging, Adult, Aged, Male, Middle Aged, Female, Imaging, Three-Dimensional, Adolescent, Brain Neoplasms, Child, Child, Preschool, Computer Simulation, Magnetic Resonance Angiography, Patient Care Planning, Software, Stereotaxic Techniques},
	file = {全文:C\:\\Users\\yochien\\Zotero\\storage\\3RE6JBXC\\Gering 等。 - 2001 - An integrated visualization system for surgical pl.pdf:application/pdf},
}

@inproceedings{pieperNAMICKitITK2006,
	title = {The {NA}-{MIC} Kit: {ITK}, {VTK}, pipelines, grids and 3D slicer as an open platform for the medical image computing community},
	doi = {10.1109/ISBI.2006.1625012},
	shorttitle = {The {NA}-{MIC} Kit},
	abstract = {Medical image computing researchers often face the problem of moving promising new algorithms from the proof of concept stage into a form compatible with clinical use. Algorithm developers lack the time and resources to engineer their code for robustness and compatibility, while end-users are anxious to try new techniques but require well designed and tested user interfaces to make practical use of them. The {NA}-{MIC} Kit is a collection of software and methodology specifically designed to address these problems and facilitate the rapid advancement of the field},
	eventtitle = {3rd {IEEE} International Symposium on Biomedical Imaging: Nano to Macro, 2006.},
	pages = {698--701},
	booktitle = {3rd {IEEE} International Symposium on Biomedical Imaging: Nano to Macro, 2006.},
	author = {Pieper, S. and Lorensen, B. and Schroeder, W. and Kikinis, R.},
	date = {2006-04},
	note = {{ISSN}: 1945-8452},
	keywords = {Testing, Algorithm design and analysis, Biomedical engineering, Biomedical imaging, Design engineering, Design methodology, Grid computing, Pipelines, Robustness, User interfaces},
}

@article{rasuliMetforminContrastMedia1998,
	title = {Metformin and contrast media: where is the conflict?},
	volume = {49},
	issn = {0846-5371},
	shorttitle = {Metformin and contrast media},
	abstract = {Intravascular administration of iodinated contrast media to patients who are receiving metformin, an oral antidiabetic agent, can result in lactic acidosis. However, this rare complication occurs only if the contrast medium causes renal failure, and the patient continues to take metformin in the presence of renal failure. Because metformin is excreted primarily by the kidneys, continued intake of metformin after the onset of renal failure results in a toxic accumulation of this drug and subsequent lactic acidosis. To avoid this complication, metformin must be withheld after the administration of the contrast agent for 48 hours, during which the contrast-induced renal failure becomes clinically apparent. If renal function is normal at 48 hours, the metformin can be restarted. There is no scientific justification for withholding metformin for 48 hours before administration of the contrast medium, as currently recommended in the package insert. The authors review the pharmacology of metformin and present a departmental policy for managing patients with diabetes who receive metformin and who require intravascular administration of iodinated contrast media.},
	pages = {161--166},
	number = {3},
	journaltitle = {Canadian Association of Radiologists Journal = Journal l'Association Canadienne Des Radiologistes},
	shortjournal = {Can Assoc Radiol J},
	author = {Rasuli, P. and Hammond, D. I.},
	date = {1998-06},
	pmid = {9640281},
	keywords = {Humans, Contrast Media, Acidosis, Lactic, Contraindications, Diabetes Mellitus, Type 2, Drug Interactions, Hypoglycemic Agents, Metformin, Renal Insufficiency},
}

@online{murphyWindowingCTRadiology,
	title = {Windowing ({CT}) {\textbar} Radiology Reference Article {\textbar} Radiopaedia.org},
	url = {https://radiopaedia.org/articles/windowing-ct?lang=us},
	abstract = {Windowing, also known as grey-level mapping, contrast stretching, histogram modification or contrast enhancement is the process in which the {CT} image greyscale component of an image is manipulated via the {CT} numbers; doing this will change the ap...},
	titleaddon = {Radiopaedia},
	author = {Murphy, Andrew},
	urldate = {2021-07-04},
	langid = {american},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\L8QHRS5E\\windowing-ct.html:text/html},
}

@online{greenwayHounsfieldUnitRadiology,
	title = {Hounsfield unit {\textbar} Radiology Reference Article {\textbar} Radiopaedia.org},
	url = {https://radiopaedia.org/articles/hounsfield-unit},
	abstract = {Hounsfield units ({HU}) are a dimensionless unit universally used in computed tomography ({CT}) scanning to express {CT} numbers in a standardized and convenient form. Hounsfield units are obtained from a linear transformation of the measured attenuati...},
	titleaddon = {Radiopaedia},
	author = {Greenway, Kyle},
	urldate = {2021-07-04},
	langid = {american},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\MJWRNW3K\\hounsfield-unit.html:text/html},
}

@incollection{levCTAngiographyCT2002,
	location = {San Diego},
	title = {{CT} Angiography and {CT} Perfusion Imaging},
	isbn = {978-0-12-693019-1},
	url = {https://www.sciencedirect.com/science/article/pii/B9780126930191500198},
	pages = {427--484},
	booktitle = {Brain Mapping: The Methods (Second Edition)},
	publisher = {Academic Press},
	author = {Lev, M. H. and Gonzalez, R. G.},
	editor = {Toga, Arthur W. and Mazziotta, John C.},
	urldate = {2021-07-04},
	date = {2002-01-01},
	langid = {english},
	doi = {10.1016/B978-012693019-1/50019-8},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\MHMR3DJA\\Lev 與 Gonzalez - 2002 - 17 - CT Angiography and CT Perfusion Imaging.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\N6KH8J2Y\\B9780126930191500198.html:text/html},
}

@online{nadrljanskiComputedTomographyRadiology,
	title = {Computed tomography {\textbar} Radiology Reference Article {\textbar} Radiopaedia.org},
	url = {https://radiopaedia.org/articles/computed-tomography},
	abstract = {Computed tomography ({CT}) scanning, also known as, especially in the older literature and textbooks, computerized axial tomography ({CAT}) scanning, is a diagnostic imaging procedure that uses x-rays to build cross-sectional images ("slices") of the...},
	titleaddon = {Radiopaedia},
	author = {Nadrljanski, Mirjan M.},
	urldate = {2021-07-05},
	langid = {american},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\H767V3K9\\computed-tomography.html:text/html},
}

@article{mckavanaghEssentialsCardiacComputerized2015,
	title = {The Essentials of Cardiac Computerized Tomography},
	volume = {4},
	issn = {2193-8261},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4675750/},
	doi = {10.1007/s40119-015-0052-0},
	abstract = {Cardiac computerized tomography ({CT}) has evolved from a research tool to an important diagnostic investigation in cardiology, and is now recommended in European, {US}, and {UK} guidelines. This review is designed to give the reader an overview of the current state of cardiac {CT}. The role of cardiac {CT} is multifaceted, and includes risk stratification, disease detection, coronary plaque quantification, defining congenital heart disease, planning for structural intervention, and, more recently, assessment of ischemia. This paper addresses basic principles as well as newer evidence.},
	pages = {117--129},
	number = {2},
	journaltitle = {Cardiology and Therapy},
	shortjournal = {Cardiol Ther},
	author = {{McKavanagh}, Peter and Walls, Gerard and {McCune}, Claire and Malloy, Jonathon and Harbinson, Mark T. and Ball, Peter A. and Donnelly, Patrick M.},
	urldate = {2021-07-05},
	date = {2015-12},
	pmid = {26536882},
	pmcid = {PMC4675750},
	file = {PubMed Central Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\YGKXGGE7\\McKavanagh 等。 - 2015 - The Essentials of Cardiac Computerized Tomography.pdf:application/pdf},
}

@article{andreucciUpdateRenalToxicity2017,
	title = {Update on the renal toxicity of iodinated contrast drugs used in clinical medicine},
	volume = {9},
	issn = {1179-1365},
	doi = {10.2147/DHPS.S122207},
	abstract = {An important side effect of diagnostic contrast drugs is contrast-induced acute kidney injury ({CI}-{AKI}; a sudden decrease in renal function) occurring 48-72 hours after injection of a contrast drug that cannot be attributed to other causes. Its existence has recently been challenged, because of some retrospective studies in which the incidence of {AKI} was not different between subjects who received a contrast drug and those who did not, even using propensity score matching to prevent selection bias. For some authors, only patients with estimated glomerular filtration rate {\textless}30 {mL}/min/1.73 m2 are at significant risk of {CI}-{AKI}. Most agree that when renal function is normal, there is no {CI}-{AKI} risk. Many experimental studies, however, are in favor of the existence of {CI}-{AKI}. Contrast drugs have been shown to cause the following changes: renal vasoconstriction, resulting in a rise in intrarenal resistance (decrease in renal blood flow and glomerular filtration rate and medullary hypoxia); epithelial vacuolization and dilatation and necrosis of proximal tubules; potentiation of angiotensin {II} effects, reducing nitric oxide ({NO}) and causing direct constriction of descending vasa recta, leading to formation of reactive oxygen species in isolated descending vasa recta of rats microperfused with a solution of iodixanol; increasing active sodium reabsorption in the thick ascending limbs of Henle's loop (increasing O2 demand and consequently medullary hypoxia); direct cytotoxic effects on endothelial and tubular epithelial cells (decrease in release of {NO} in vasa recta); and reducing cell survival, due to decreased activation of Akt and {ERK}1/2, kinases involved in cell survival/proliferation. Prevention is mainly based on extracellular volume expansion, statins, and N-acetylcysteine; conflicting results have been obtained with nebivolol, furosemide, calcium-channel blockers, theophylline, and hemodialysis.},
	pages = {25--37},
	journaltitle = {Drug, Healthcare and Patient Safety},
	shortjournal = {Drug Healthc Patient Saf},
	author = {Andreucci, Michele and Faga, Teresa and Serra, Raffaele and De Sarro, Giovambattista and Michael, Ashour},
	date = {2017},
	pmid = {28579836},
	pmcid = {PMC5447694},
	keywords = {acute kidney injury, {AKI}, {ARF}, contrast media, intracellular signaling, renal failure},
	file = {全文:C\:\\Users\\yochien\\Zotero\\storage\\CC4MLS2D\\Andreucci 等。 - 2017 - Update on the renal toxicity of iodinated contrast.pdf:application/pdf},
}

@online{saljoughianIntravenousRadiocontrastMedia2012,
	title = {Intravenous Radiocontrast Media: A Review of Allergic Reactions},
	url = {https://www.uspharmacist.com/article/intravenous-radiocontrast-media-a-review-of-allergic-reactions},
	shorttitle = {Intravenous Radiocontrast Media},
	author = {Saljoughian, Manouchehr},
	urldate = {2021-07-06},
	date = {2012-05-22},
	langid = {english},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\V9NALBET\\intravenous-radiocontrast-media-a-review-of-allergic-reactions.html:text/html},
}

@inproceedings{jiangTumorAwareAdversarialDomain2018,
	location = {Cham},
	title = {Tumor-Aware, Adversarial Domain Adaptation from {CT} to {MRI} for Lung Cancer Segmentation},
	isbn = {978-3-030-00934-2},
	doi = {10.1007/978-3-030-00934-2_86},
	series = {Lecture Notes in Computer Science},
	abstract = {We present an adversarial domain adaptation based deep learning approach for automatic tumor segmentation from T2-weighted {MRI}. Our approach is composed of two steps: (i) a tumor-aware unsupervised cross-domain adaptation ({CT} to {MRI}), followed by (ii) semi-supervised tumor segmentation using Unet trained with synthesized and limited number of original {MRIs}. We introduced a novel target specific loss, called tumor-aware loss, for unsupervised cross-domain adaptation that helps to preserve tumors on synthesized {MRIs} produced from {CT} images. In comparison, state-of-the art adversarial networks trained without our tumor-aware loss produced {MRIs} with ill-preserved or missing tumors. All networks were trained using labeled {CT} images from 377 patients with non-small cell lung cancer obtained from the Cancer Imaging Archive and unlabeled T2w {MRIs} from a completely unrelated cohort of 6 patients with pre-treatment and 36 on-treatment scans. Next, we combined 6 labeled pre-treatment {MRI} scans with the synthesized {MRIs} to boost tumor segmentation accuracy through semi-supervised learning. Semi-supervised training of cycle-{GAN} produced a segmentation accuracy of 0.66 computed using Dice Score Coefficient ({DSC}). Our method trained with only synthesized {MRIs} produced an accuracy of 0.74 while the same method trained in semi-supervised setting produced the best accuracy of 0.80 on test. Our results show that tumor-aware adversarial domain adaptation helps to achieve reasonably accurate cancer segmentation from limited {MRI} data by leveraging large {CT} datasets.},
	pages = {777--785},
	booktitle = {Medical Image Computing and Computer Assisted Intervention – {MICCAI} 2018},
	publisher = {Springer International Publishing},
	author = {Jiang, Jue and Hu, Yu-Chi and Tyagi, Neelam and Zhang, Pengpeng and Rimner, Andreas and Mageras, Gig S. and Deasy, Joseph O. and Veeraraghavan, Harini},
	editor = {Frangi, Alejandro F. and Schnabel, Julia A. and Davatzikos, Christos and Alberola-López, Carlos and Fichtinger, Gabor},
	date = {2018},
	langid = {english},
	file = {Springer Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\MJ56F73Y\\Jiang 等。 - 2018 - Tumor-Aware, Adversarial Domain Adaptation from CT.pdf:application/pdf},
}

@inproceedings{kanitsarCPRCurvedPlanar2002,
	title = {{CPR} - curved planar reformation},
	doi = {10.1109/VISUAL.2002.1183754},
	abstract = {Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation ({CPR}). We present three different methods to generate {CPR} images. A tube-phantom was scanned with computed tomography ({CT}) to illustrate the properties of the different {CPR} methods. Furthermore we introduce enhancements to these methods: thick-{CPR}, rotating-{CPR} and multi-path-{CPR}.},
	eventtitle = {{IEEE} Visualization, 2002. {VIS} 2002.},
	pages = {37--44},
	booktitle = {{IEEE} Visualization, 2002. {VIS} 2002.},
	author = {Kanitsar, A. and Fleischmann, D. and Wegenkittl, R. and Felkel, P. and Groller, E.},
	date = {2002-10},
	keywords = {Computed tomography, Biomedical imaging, Blood vessels, Chromium, Computer displays, Computer graphics, Data visualization, Image generation, Magnetic resonance imaging, Radiology},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\I2BCLUWB\\Kanitsar 等。 - 2002 - CPR - curved planar reformation.pdf:application/pdf},
}

@inproceedings{chenCoronaryArterySegmentation2019,
	title = {Coronary artery Segmentation in Cardiac {CT} Angiography Using 3D Multi-Channel U-net},
	url = {https://openreview.net/forum?id=r1g1GbCV54},
	abstract = {Vessel stenosis is a major risk factor in cardiovascular diseases ({CVD}). To analyze the degree of vessel stenosis for supporting the treatment management, extraction of coronary artery area from...},
	eventtitle = {International Conference on Medical Imaging with Deep Learning -- Extended Abstract Track},
	author = {Chen, Yo-Chuan and Lin, Yi-Chen and Wang, Ching-Ping and Lee, Chia-Yen and Wang, Tzung-Dau and Lee, Wen-Jeng and Chen, Chung-Ming},
	urldate = {2021-08-13},
	date = {2019-04-17},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\Y4DL5BBD\\Chen 等。 - 2019 - Coronary artery Segmentation in Cardiac CT Angiogr.pdf:application/pdf;Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\8XQEHSGN\\forum.html:text/html},
}

@inproceedings{cicek3DUNetLearning2016,
	location = {Cham},
	title = {3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation},
	isbn = {978-3-319-46723-8},
	doi = {10.1007/978-3-319-46723-8_49},
	series = {Lecture Notes in Computer Science},
	shorttitle = {3D U-Net},
	abstract = {This paper introduces a network for volumetric segmentation that learns from sparsely annotated volumetric images. We outline two attractive use cases of this method: (1) In a semi-automated setup, the user annotates some slices in the volume to be segmented. The network learns from these sparse annotations and provides a dense 3D segmentation. (2) In a fully-automated setup, we assume that a representative, sparsely annotated training set exists. Trained on this data set, the network densely segments new volumetric images. The proposed network extends the previous u-net architecture from Ronneberger et al. by replacing all 2D operations with their 3D counterparts. The implementation performs on-the-fly elastic deformations for efficient data augmentation during training. It is trained end-to-end from scratch, i.e., no pre-trained network is required. We test the performance of the proposed method on a complex, highly variable 3D structure, the Xenopus kidney, and achieve good results for both use cases.},
	pages = {424--432},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention – {MICCAI} 2016},
	publisher = {Springer International Publishing},
	author = {Çiçek, Özgün and Abdulkadir, Ahmed and Lienkamp, Soeren S. and Brox, Thomas and Ronneberger, Olaf},
	editor = {Ourselin, Sebastien and Joskowicz, Leo and Sabuncu, Mert R. and Unal, Gozde and Wells, William},
	date = {2016},
	langid = {english},
	keywords = {Convolutional neural networks, 3D, Biomedical volumetric image segmentation, Fully-automated, Semi-automated, Sparse annotation, Xenopus kidney},
	file = {Springer Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\Q56UDFRQ\\Çiçek 等。 - 2016 - 3D U-Net Learning Dense Volumetric Segmentation f.pdf:application/pdf},
}

@inproceedings{zhuUnpairedImagetoImageTranslation2017,
	title = {Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks},
	doi = {10.1109/ICCV.2017.244},
	abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G : X → Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F : Y → X and introduce a cycle consistency loss to push F(G(X)) ≈ X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
	eventtitle = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
	pages = {2242--2251},
	booktitle = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
	author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
	date = {2017-10},
	note = {{ISSN}: 2380-7504},
	keywords = {Training, Semantics, Extraterrestrial measurements, Graphics, Painting, Training data},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\yochien\\Zotero\\storage\\RZP3XK77\\8237506.html:text/html;送出的版本:C\:\\Users\\yochien\\Zotero\\storage\\WGSFGMEF\\Zhu 等。 - 2017 - Unpaired Image-to-Image Translation Using Cycle-Co.pdf:application/pdf},
}

@article{kjerlandSegmentationCoronaryArteries2017a,
	title = {Segmentation of Coronary Arteries from {CT}-scans of the heart using Deep Learning},
	url = {https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/2456361},
	abstract = {Image segmentation is an important tool in several fields. One is medical image computing where the images are divided into regions based on tissue type and organ, which can further be used for visualization and diagnosis. Due to the large amount of data produced by modern imaging modalities such as {CT} and {MRI}, the process of manual or semi-automatic segmentation is time consuming, tedious and introduces bias by clinical experts. Recent advances in the field of deep learning has given rise to several fully automatic methods for robust segmentation on a large variety of segmentation tasks. In this thesis the use of a 3D convolutional neural network architecture is used on three different segmentation tasks is explored. These tasks are coronary artery segmentation, brain tumor segmentation and digital rock segmentation. 

Coronary artery disease is the leading cause of death in Europe. Diagnosis of the disease is today done by invasive methods, but research on using computational fluid dynamics to model the blood flow based on non-invasive imaging show great promise. In this thesis a method for fully automatic segmentation of the coronary arteries based on deep learning is proposed, implemented and evaluated on a dataset provided by St. Olavs Hospital. The dataset contains manual segmentations performed by a clinical expert. The proposed method uses two neural networks trained on aorta segmentation and coronary segmentation respectively and is able to segment the complete coronary artery tree in some test images, but fails to segment all branches in the rest of the images.  

For the brain tumor segmentation task a network is trained and evaluated on a dataset provided by the Norwegian National Advisory Unit for Ultrasound and Image Guided Therapy ({USIGT}). The results show that the deep learning method is able to produce good segmentations fully automatically. These segmentations do however inlcude some spurious responses.

Digital Rocks technology is based on using high resolution 3D microscopy imaging to create models describing reservoir rock. A network was trained and evaluated on a digital rock dataset provided by {FEI}. The results show that the network is able to produce good segmentations fully automatically.},
	author = {Kjerland, Øyvind},
	urldate = {2021-08-14},
	date = {2017},
	note = {Accepted: 2017-09-22T14:00:45Z
Publisher: {NTNU}},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\39Q2YDP5\\2456361.html:text/html;Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\TYILDHVY\\Kjerland - 2017 - Segmentation of Coronary Arteries from CT-scans of.pdf:application/pdf},
}

@incollection{ogobuiroAnatomyThoraxHeart2021,
	location = {Treasure Island ({FL})},
	title = {Anatomy, Thorax, Heart Coronary Arteries},
	rights = {Copyright © 2021, {StatPearls} Publishing {LLC}.},
	url = {http://www.ncbi.nlm.nih.gov/books/NBK534790/},
	abstract = {The coronary arteries run along the coronary sulcus of the myocardium of the heart. Their main function is to supply blood to the heart. This is a crucial function for myocardial function and subsequently homeostasis of the body. The arrangement of coronary arteries varies among people significantly.},
	booktitle = {{StatPearls}},
	publisher = {{StatPearls} Publishing},
	author = {Ogobuiro, Ifeanyichukwu and Wehrle, Chase J. and Tuma, Faiz},
	urldate = {2021-08-22},
	date = {2021},
	pmid = {30521211},
	file = {Printable HTML:C\:\\Users\\yochien\\Zotero\\storage\\7RXMJGQI\\NBK534790.html:text/html},
}

@book{ogobuiroAnatomyThoraxHeart2021a,
	title = {Anatomy, Thorax, Heart Coronary Arteries},
	url = {https://www.ncbi.nlm.nih.gov/books/NBK534790/},
	abstract = {The coronary arteries run along the coronary sulcus of the myocardium of the heart. Their main function is to supply blood to the heart. This is a crucial function for myocardial function and subsequently homeostasis of the body. The arrangement of coronary arteries varies among people significantly.},
	publisher = {{StatPearls} Publishing},
	author = {Ogobuiro, Ifeanyichukwu and Wehrle, Chase J. and Tuma, Faiz},
	urldate = {2021-08-22},
	date = {2021-07-28},
	langid = {pinyin},
	pmid = {30521211},
	note = {Publication Title: {StatPearls} [Internet]},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\VPEVZIRE\\NBK534790.html:text/html},
}

@online{AtherosclerosisAmericanHeart,
	title = {Atherosclerosis {\textbar} American Heart Association},
	url = {https://www.heart.org/en/health-topics/cholesterol/about-cholesterol/atherosclerosis},
	urldate = {2021-08-22},
	file = {Atherosclerosis | American Heart Association:C\:\\Users\\yochien\\Zotero\\storage\\6Z2P73MK\\atherosclerosis.html:text/html},
}

@online{AtherosclerosisNHLBINIH,
	title = {Atherosclerosis {\textbar} {NHLBI}, {NIH}},
	url = {https://www.nhlbi.nih.gov/health-topics/atherosclerosis},
	urldate = {2021-08-22},
	file = {Atherosclerosis | NHLBI, NIH:C\:\\Users\\yochien\\Zotero\\storage\\65BMI9W9\\atherosclerosis.html:text/html},
}

@book{rehmanPhysiologyCoronaryCirculation2021,
	title = {Physiology, Coronary Circulation},
	url = {https://www.ncbi.nlm.nih.gov/books/NBK482413/},
	abstract = {The heart is highly metabolically active and boasts the highest oxygen consumption by mass of any organ. This demand for oxygen is met by the coronary circulation, which is responsible for delivering blood to the myocardium and represents approximately 5\% of cardiac output.[1] Adequate blood flow through the coronary vessels is critical to avoid ischemia and maintain the integrity of the myocardial tissue.},
	publisher = {{StatPearls} Publishing},
	author = {Rehman, Saad and Khan, Amir and Rehman, Afzal},
	urldate = {2021-08-22},
	date = {2021-05-09},
	pmid = {29494020},
	note = {Publication Title: {StatPearls} [Internet]},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\FUNFKW2E\\NBK482413.html:text/html},
}

@book{ojhaMyocardialInfarction2021,
	title = {Myocardial Infarction},
	url = {https://www.ncbi.nlm.nih.gov/books/NBK537076/},
	abstract = {Myocardial infarction ({MI}), colloquially known as “heart attack,” is caused by decreased or complete cessation of blood flow to a portion of the myocardium. Myocardial infarction may be “silent” and go undetected, or it could be a catastrophic event leading to hemodynamic deterioration and sudden death.[1] Most myocardial infarctions are due to underlying coronary artery disease, the leading cause of death in the United States. With coronary artery occlusion, the myocardium is deprived of oxygen. Prolonged deprivation of oxygen supply to the myocardium can lead to myocardial cell death and necrosis.[2] Patients can present with chest discomfort or pressure that can radiate to the neck, jaw, shoulder, or arm. In addition to the history and physical exam, myocardial ischemia may be associated with {ECG} changes and elevated biochemical markers such as cardiac troponins.[3][4]},
	publisher = {{StatPearls} Publishing},
	author = {Ojha, Niranjan and Dhamoon, Amit S.},
	urldate = {2021-08-22},
	date = {2021-08-11},
	langid = {english},
	pmid = {30725761},
	note = {Publication Title: {StatPearls} [Internet]},
	file = {Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\72RADQ3Z\\NBK537076.html:text/html},
}

@article{singh3DDeepLearning2020,
	title = {3D Deep Learning on Medical Images: A Review},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7570704/},
	doi = {10.3390/s20185097},
	shorttitle = {3D Deep Learning on Medical Images},
	abstract = {The rapid advancements in machine learning, graphics processing technologies and the availability of medical imaging data have led to a rapid increase in the use of deep learning models in the medical domain. This was exacerbated by the rapid advancements in convolutional neural network ({CNN}) based architectures, which were adopted by the medical imaging community to assist clinicians in disease diagnosis. Since the grand success of {AlexNet} in 2012, {CNNs} have been increasingly used in medical image analysis to improve the efficiency of human clinicians. In recent years, three-dimensional (3D) {CNNs} have been employed for the analysis of medical images. In this paper, we trace the history of how the 3D {CNN} was developed from its machine learning roots, we provide a brief mathematical description of 3D {CNN} and provide the preprocessing steps required for medical images before feeding them to 3D {CNNs}. We review the significant research in the field of 3D medical imaging analysis using 3D {CNNs} (and its variants) in different medical areas such as classification, segmentation, detection and localization. We conclude by discussing the challenges associated with the use of 3D {CNNs} in the medical imaging domain (and the use of deep learning models in general) and possible future trends in the field.},
	pages = {5097},
	number = {18},
	journaltitle = {Sensors (Basel, Switzerland)},
	shortjournal = {Sensors (Basel)},
	author = {Singh, Satya P. and Wang, Lipo and Gupta, Sukrit and Goli, Haveesh and Padmanabhan, Parasuraman and Gulyás, Balázs},
	urldate = {2021-08-22},
	date = {2020-09-07},
	pmid = {32906819},
	pmcid = {PMC7570704},
	file = {PubMed Central Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\AMLZKBJH\\Singh 等。 - 2020 - 3D Deep Learning on Medical Images A Review.pdf:application/pdf},
}

@inproceedings{moeskopsDeepLearningMultitask2016,
	location = {Cham},
	title = {Deep Learning for Multi-task Medical Image Segmentation in Multiple Modalities},
	isbn = {978-3-319-46723-8},
	doi = {10.1007/978-3-319-46723-8_55},
	series = {Lecture Notes in Computer Science},
	abstract = {Automatic segmentation of medical images is an important task for many clinical applications. In practice, a wide range of anatomical structures are visualised using different imaging modalities. In this paper, we investigate whether a single convolutional neural network ({CNN}) can be trained to perform different segmentation tasks.A single {CNN} is trained to segment six tissues in {MR} brain images, the pectoral muscle in {MR} breast images, and the coronary arteries in cardiac {CTA}. The {CNN} therefore learns to identify the imaging modality, the visualised anatomical structures, and the tissue classes.For each of the three tasks (brain {MRI}, breast {MRI} and cardiac {CTA}), this combined training procedure resulted in a segmentation performance equivalent to that of a {CNN} trained specifically for that task, demonstrating the high capacity of {CNN} architectures. Hence, a single system could be used in clinical practice to automatically perform diverse segmentation tasks without task-specific training.},
	pages = {478--486},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention – {MICCAI} 2016},
	publisher = {Springer International Publishing},
	author = {Moeskops, Pim and Wolterink, Jelmer M. and van der Velden, Bas H. M. and Gilhuijs, Kenneth G. A. and Leiner, Tim and Viergever, Max A. and Išgum, Ivana},
	editor = {Ourselin, Sebastien and Joskowicz, Leo and Sabuncu, Mert R. and Unal, Gozde and Wells, William},
	date = {2016},
	langid = {english},
	keywords = {Brain {MRI}, Breast {MRI}, Cardiac {CTA}, Convolutional neural networks, Deep learning, Medical image segmentation},
	file = {Springer Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\PATXNCI9\\Moeskops 等。 - 2016 - Deep Learning for Multi-task Medical Image Segment.pdf:application/pdf},
}

@article{porterHippocampusSegmentationNoncontrast2020a,
	title = {Hippocampus segmentation on noncontrast {CT} using deep learning},
	volume = {47},
	issn = {2473-4209},
	doi = {10.1002/mp.14098},
	abstract = {{PURPOSE}: Accurate segmentation of the hippocampus for hippocampal avoidance whole-brain radiotherapy currently requires high-resolution magnetic resonance imaging ({MRI}) in addition to neuroanatomic expertise for manual segmentation. Removing the need for {MR} images to identify the hippocampus would reduce planning complexity, the need for a treatment planning {MR} imaging session, potential uncertainties associated with {MRI}-computed tomography ({CT}) image registration, and cost. Three-dimensional (3D) deep convolutional network models have the potential to automate hippocampal segmentation. In this study, we investigate the accuracy and reliability of hippocampal segmentation by automated deep learning models from {CT} alone and compare the accuracy to experts using {MRI} fusion.
{METHODS}: Retrospectively, 390 Gamma Knife patients with high-resolution {CT} and {MR} images were collected. Following the {RTOG} 0933 guidelines, images were rigidly fused, and a neuroanatomic expert contoured the hippocampus on the {MR}, then transferred the contours to {CT}. Using a calculated cranial centroid, the image volumes were cropped to 200 × 200 × 35 voxels, which were used to train four models, including our proposed Attention-Gated 3D {ResNet} ({AG}-3D {ResNet}). These models were then compared with results from a nested tenfold validation. From the predicted test set volumes, we calculated the 100\% Hausdorff distance ({HD}). Acceptability was assessed using the {RTOG} 0933 protocol criteria, and contours were considered passing with {HD} ≤ 7 mm.
{RESULTS}: The bilateral hippocampus passing rate across all 90 models trained in the nested cross-fold validation was 80.2\% for {AG}-3D {ResNet}, which performs with a comparable pass rate (P = 0.3345) to physicians during centralized review for the {RTOG} 0933 Phase {II} clinical trial.
{CONCLUSIONS}: Our proposed {AG}-3D {ResNet}'s segmentation of the hippocampus from noncontrast {CT} images alone are comparable to those obtained by participating physicians from the {RTOG} 0933 Phase {II} clinical trial.},
	pages = {2950--2961},
	number = {7},
	journaltitle = {Medical Physics},
	shortjournal = {Med Phys},
	author = {Porter, Evan and Fuentes, Patricia and Siddiqui, Zaid and Thompson, Andrew and Levitin, Ronald and Solis, David and Myziuk, Nick and Guerrero, Thomas},
	date = {2020-07},
	pmid = {32065401},
	keywords = {attention gating, {CT}, deep learning, Deep Learning, hippocampus, Hippocampus, Humans, Image Processing, Computer-Assisted, Magnetic Resonance Imaging, Reproducibility of Results, {ResNet}, Retrospective Studies, segmentation, Tomography, X-Ray Computed, U-Net, whole-brain radiotherapy},
}

@article{patelIntracerebralHaemorrhageSegmentation2019,
	title = {Intracerebral Haemorrhage Segmentation in Non-Contrast {CT}},
	volume = {9},
	rights = {2019 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-019-54491-6},
	doi = {10.1038/s41598-019-54491-6},
	abstract = {A 3-dimensional (3D) convolutional neural network is presented for the segmentation and quantification of spontaneous intracerebral haemorrhage ({ICH}) in non-contrast computed tomography ({NCCT}). The method utilises a combination of contextual information on multiple scales for fast and fully automatic dense predictions. To handle a large class imbalance present in the data, a weight map is introduced during training. The method was evaluated on two datasets of 25 and 50 patients respectively. The reference standard consisted of manual annotations for each {ICH} in the dataset. Quantitative analysis showed a median Dice similarity coefficient of 0.91 [0.87–0.94] and 0.90 [0.85–0.92] for the two test datasets in comparison to the reference standards. Evaluation of a separate dataset of 5 patients for the assessment of the observer variability produced a mean Dice similarity coefficient of 0.95 ± 0.02 for the inter-observer variability and 0.97 ± 0.01 for the intra-observer variability. The average prediction time for an entire volume was 104 ± 15 seconds. The results demonstrate that the method is accurate and approaches the performance of expert manual annotation.},
	pages = {17858},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Patel, Ajay and Schreuder, Floris H. B. M. and Klijn, Catharina J. M. and Prokop, Mathias and Ginneken, Bram van and Marquering, Henk A. and Roos, Yvo B. W. E. M. and Baharoglu, M. Irem and Meijer, Frederick J. A. and Manniesing, Rashindra},
	urldate = {2021-08-22},
	date = {2019-11-28},
	langid = {english},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Brain imaging;Computed tomography;Computer science;Stroke
Subject\_term\_id: brain-imaging;computed-tomography;computer-science;stroke},
	file = {Full Text PDF:C\:\\Users\\yochien\\Zotero\\storage\\GYCRLBHU\\Patel 等。 - 2019 - Intracerebral Haemorrhage Segmentation in Non-Cont.pdf:application/pdf;Snapshot:C\:\\Users\\yochien\\Zotero\\storage\\HIQLG9XU\\s41598-019-54491-6.html:text/html},
}